{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import random \n",
    "import time \n",
    "import os \n",
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#验证码图片的存放路径\n",
    "captcha_image_path = r'C:\\Users\\chenlonghua.JW\\Documents\\GitHub\\data\\captcha\\images'\n",
    "#验证码图片的宽度\n",
    "captcha_image_width = 160 \n",
    "#验证码图片的高度\n",
    "captcha_image_height = 60 \n",
    "\n",
    "char_set_len =10 \n",
    "captcha_len =4 \n",
    "\n",
    "#60%的验证码图片放入训练集中\n",
    "train_image_percent = 0.6 \n",
    "#训练集，用于训练的验证码图片的文件名\n",
    "training_image_name = [] \n",
    "#验证集，用于模型验证的验证码图片的文件名\n",
    "validation_image_name = [] \n",
    "\n",
    "#存放训练好的模型的路径\n",
    "model_save_path = r'C:\\Users\\chenlonghua.JW\\Documents\\GitHub\\data\\captcha\\models'\n",
    "\n",
    "def get_image_file_name(imgPath=captcha_image_path):\n",
    "    fileName = [] \n",
    "    total = 0 \n",
    "    for filePath in os.listdir(imgPath):\n",
    "        captcha_name = filePath.split('\\\\')[-1]\n",
    "        fileName.append(captcha_name)\n",
    "        total +=1 \n",
    "    return fileName,total \n",
    "\n",
    "'''\n",
    "将验证码转换为训练时用的标签向量，维数是40 \n",
    "例如，验证码是'0296',则对应的标签是\n",
    "[1 0 0 0 0 0 0 0 0 0\n",
    "0 0 1 0 0 0 0 0 0 0\n",
    "0 0 0 0 0 0 0 0 0 1\n",
    "0 0 0 0 0 0 1 0 0 0]\n",
    "'''\n",
    "def name2label(name):\n",
    "    label = np.zeros(captcha_len * char_set_len)\n",
    "    for i,c in enumerate(name):\n",
    "        idx = i *char_set_len + ord(c) - ord('0')\n",
    "        label[idx] =1 \n",
    "    return label \n",
    "\n",
    "#取得验证码图片的数据以及它的标签\n",
    "def get_data_and_label(fileName,filePath=captcha_image_path):\n",
    "    pathName = os.path.join(filePath,fileName)\n",
    "    img = Image.open(pathName)\n",
    "    #转为灰度图\n",
    "    img = img.convert('L')\n",
    "    image_array = np.array(img)\n",
    "    image_data = image_array.flatten()/255 \n",
    "    image_label = name2label(fileName[0:captcha_len])\n",
    "    return image_data,image_label \n",
    "\n",
    "#生成一个训练batch \n",
    "def get_next_batch(batchSize=32,trainOrTest='train',step=0):\n",
    "    batch_data = np.zeros([batchSize,captcha_image_width * captcha_image_height])\n",
    "    batch_label = np.zeros([batchSize,captcha_len * char_set_len])\n",
    "    fileNameList = training_image_name \n",
    "    if trainOrTest =='validate':\n",
    "        fileNameList = validation_image_name \n",
    "    \n",
    "    totalNumber = len(fileNameList)\n",
    "    indexStart = step * batchSize \n",
    "    for i in range(batchSize):\n",
    "        index = (i +indexStart) %totalNumber \n",
    "        name =fileNameList[index]\n",
    "        img_data,img_label = get_data_and_label(name)\n",
    "        batch_data[i,:] = img_data \n",
    "        batch_label[i,:] = img_label \n",
    "    return batch_data,batch_label \n",
    "\n",
    "        \n",
    "#构建卷积神经网络并训练\n",
    "def train_data_with_CNN():\n",
    "    #初始化权值\n",
    "    def weight_variable(shape,name='weight'):\n",
    "        init = tf.truncated_normal(shape,stddev=0.1)\n",
    "        var = tf.Variable(initial_value=init,name=name)\n",
    "        return var \n",
    "    #初始化偏置项\n",
    "    def bias_variable(shape,name='bias'):\n",
    "        init = tf.constant(0.1,shape=shape)\n",
    "        var = tf.Variable(init,name=name)\n",
    "        return var \n",
    "    #卷积\n",
    "    def conv2d(x,W,name='conv2d'):\n",
    "        return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME',name=name)\n",
    "    #池化\n",
    "    def max_pool_2(x,name='maxpool'):\n",
    "        return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME',name=name)\n",
    "    \n",
    "    #输入层\n",
    "    #请注意X的name，在测试model时会用到它\n",
    "    X = tf.placeholder(tf.float32,[None,captcha_image_width * captcha_image_height],name='input-data')\n",
    "    Y = tf.placeholder(tf.float32,[None,captcha_len * char_set_len],name='label-input')\n",
    "    x_input = tf.reshape(X,[-1,captcha_image_height,captcha_image_width,1],name='x-input')  #shape=(?, 60, 160, 1)\n",
    "\n",
    "    #dropout,防止过拟合\n",
    "    #请注意keep_prob的name，在测试model时会用到它\n",
    "    keep_prob = tf.placeholder(tf.float32,name='keep-prob')\n",
    "    \n",
    "    #第一层卷积\n",
    "    W_conv1 = weight_variable([5,5,1,32],'W_conv1')\n",
    "    B_conv1 = bias_variable([32],'B_conv1')\n",
    "    conv1 = tf.nn.relu(conv2d(x_input,W_conv1,'conv1') + B_conv1)\n",
    "    conv1 = max_pool_2(conv1,'conv1-pool')\n",
    "    conv1 = tf.nn.dropout(conv1,keep_prob)   #shape=(?, 30, 80, 32)\n",
    "    print('conv1:',conv1)\n",
    "    \n",
    "    #第二层卷积\n",
    "    W_conv2 = weight_variable([5,5,32,64],'W_conv2')\n",
    "    B_conv2 = bias_variable([64],'B_conv2')\n",
    "    conv2 = tf.nn.relu(conv2d(conv1,W_conv2,'conv2') + B_conv2)\n",
    "    conv2 = max_pool_2(conv2,'conv2-pool')\n",
    "    conv2 = tf.nn.dropout(conv2,keep_prob)   #shape=(?, 15, 40, 64)\n",
    "    print('conv2:',conv2)\n",
    "    #第三层卷积\n",
    "    W_conv3 = weight_variable([5,5,64,64],'W_conv3')\n",
    "    B_conv3 = bias_variable([64],'B_conv3')\n",
    "    conv3 = tf.nn.relu(conv2d(conv2,W_conv3,'conv3') + B_conv3)\n",
    "    conv3 = max_pool_2(conv3,'conv3-pool')\n",
    "    conv3 = tf.nn.dropout(conv3,keep_prob) #shape=(?, 8, 20, 64) \n",
    "    print('conv3:',conv3)\n",
    "    #全连接层\n",
    "    #每次池化后，图片的宽度和高度均缩小为原来的一半，讲过上面的三次池化，高度和宽度均缩小8倍\n",
    "    W_fc1 = weight_variable([20*8*64,1024],'W_fc1')\n",
    "    B_fc1 = bias_variable([1024],'B_fc1')\n",
    "    fc1 = tf.reshape(conv3,[-1,20*8*64])\n",
    "    fc1 = tf.nn.relu(tf.add(tf.matmul(fc1,W_fc1),B_fc1))\n",
    "    fc1 = tf.nn.dropout(fc1,keep_prob)    #shape=(?, 1024)\n",
    "    print('fc1:',fc1)\n",
    "    #输出层\n",
    "    W_fc2 = weight_variable([1024,captcha_len * char_set_len],'W_fc2')\n",
    "    B_fc2 = bias_variable([captcha_len * char_set_len],'B_Fc2')\n",
    "    output = tf.add(tf.matmul(fc1,W_fc2),B_fc2,'output')     #shape=(?, 40)\n",
    "    print('output:',output)\n",
    "    \n",
    "    #损失函数\n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y,logits=output))\n",
    "    #优化函数\n",
    "    optimizer = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "    \n",
    "    predict =tf.reshape(output,[-1,captcha_len,char_set_len],name='predict')\n",
    "    labels = tf.reshape(Y,[-1,captcha_len,char_set_len],name='labels')\n",
    "    \n",
    "    #预测结果\n",
    "    #请注意predict_max_idx 的name，在测试model时会用到它 \n",
    "    predict_max_idx = tf.argmax(predict,axis=2,name='predict_max_idx')\n",
    "    labels_max_idx = tf.argmax(labels,axis=2,name='labels_max_idx')\n",
    "    predict_correct_vec = tf.equal(predict_max_idx,labels_max_idx)\n",
    "    accuracy = tf.reduce_mean(tf.cast(predict_correct_vec,tf.float32))\n",
    "    \n",
    "    saver = tf.train.Saver() \n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        steps = 0 \n",
    "        for epoch in range(6000):\n",
    "            train_data,train_label = get_next_batch(64,'train',steps)\n",
    "            sess.run(optimizer,feed_dict={X:train_data,Y:train_label,keep_prob:0.75})\n",
    "            if steps %100==0:\n",
    "                test_data,test_label = get_next_batch(100,'validate',steps)\n",
    "                acc = sess.run(accuracy,feed_dict={X:test_data,Y:test_label,keep_prob:1.0})\n",
    "                print('steps=%d,accuracy=%f' % (steps,acc))\n",
    "                if acc >0.99:\n",
    "                    saver.save(sess,model_save_path+'\\\\'+\"crack_captcha.model\", global_step=steps)\n",
    "                    break \n",
    "            steps +=1 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1: Tensor(\"dropout_50/mul:0\", shape=(?, 30, 80, 32), dtype=float32)\n",
      "conv2: Tensor(\"dropout_51/mul:0\", shape=(?, 15, 40, 64), dtype=float32)\n",
      "conv3: Tensor(\"dropout_52/mul:0\", shape=(?, 8, 20, 64), dtype=float32)\n",
      "fc1: Tensor(\"dropout_53/mul:0\", shape=(?, 1024), dtype=float32)\n",
      "output: Tensor(\"output_10:0\", shape=(?, 40), dtype=float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-d45ae9ca1741>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mvalidation_image_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_filename_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrainImageNumner\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_data_with_CNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'training finished'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-ee4827d91591>\u001b[0m in \u001b[0;36mtrain_data_with_CNN\u001b[0;34m()\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0minit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1291\u001b[0m                 run_metadata):\n\u001b[1;32m   1292\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1294\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         graph_def, self._current_version = self._graph._as_graph_def(\n\u001b[1;32m   1348\u001b[0m             \u001b[0mfrom_version\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_current_version\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m             add_shapes=self._add_shapes)\n\u001b[0m\u001b[1;32m   1350\u001b[0m         \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_def\u001b[0;34m(self, from_version, add_shapes)\u001b[0m\n\u001b[1;32m   2729\u001b[0m             graph.node[-1].attr[\"_output_shapes\"].list.shape.extend(\n\u001b[1;32m   2730\u001b[0m                 [output.get_shape().as_proto() for output in op.outputs])\n\u001b[0;32m-> 2731\u001b[0;31m           \u001b[0mbytesize\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2732\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mbytesize\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m<<\u001b[0m \u001b[1;36m31\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mbytesize\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2733\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"GraphDef cannot be larger than 2GB.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mByteSize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListFields\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m         \u001b[0msize\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mfield_descriptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfield_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mtag_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_bytes\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0msize\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag_bytes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_bytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\encoder.py\u001b[0m in \u001b[0;36mFieldSize\u001b[0;34m(map_value)\u001b[0m\n\u001b[1;32m    358\u001b[0m       \u001b[1;31m# duplication. For message map, value.ByteSize() should be called to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m       \u001b[1;31m# update the status.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m       \u001b[0mentry_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmessage_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_concrete_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m       \u001b[0mtotal\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmessage_sizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentry_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mis_message_map\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpp_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_FieldDescriptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCPPTYPE_MESSAGE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         \u001b[0mcopy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m         \u001b[0mnew_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfield_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfield_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mMakeSubMessageDefault\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0mmessage_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mMakeSubMessageDefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmessage_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_concrete_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m       result._SetListener(\n\u001b[1;32m    427\u001b[0m           \u001b[0m_OneofListener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_byte_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_byte_size_dirty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    image_filename_list ,total = get_image_file_name(captcha_image_path)\n",
    "    random.seed(time.time())\n",
    "    #打乱顺序\n",
    "    random.shuffle(image_filename_list)\n",
    "    trainImageNumner = int(total * train_image_percent)\n",
    "    #测试集\n",
    "    training_image_name = image_filename_list[:trainImageNumner]\n",
    "    #验证集\n",
    "    validation_image_name = image_filename_list[trainImageNumner:]\n",
    "    \n",
    "    train_data_with_CNN()\n",
    "    print('training finished')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
